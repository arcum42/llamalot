# LlamaLot

A comprehensive wxPython-based GUI application for managing and interacting with Ollama models, featuring advanced chat capabilities, conversation history, and intelligent model management.

## Features

### üîç Embeddings & RAG Support

- **Document Collections**: Create and manage ChromaDB collections for semantic search
- **RAG Integration**: Retrieve relevant context for chat conversations
- **Vector Search**: Semantic similarity search across document collections
- **Multiple Embedding Models**: Support for various Ollama embedding models
- **Persistent Storage**: Local ChromaDB storage with collection management

### üéØ Core Functionality

- **Model Management**: List, install, delete, and get detailed information about Ollama models
- **Interactive Chat Interface**: Real-time streaming chat with any loaded model
- **Vision Support**: Full image analysis capabilities for vision models (LLaVA, Llama 3.2 Vision, etc.)
- **Model Creation**: Built-in Modelfile editor with syntax highlighting and model creation wizard

### ÔøΩÔ∏è Advanced Batch Processing

- **Multi-Image Processing**: Process multiple images with vision models simultaneously
- **File Suffix Support**: Flexible file naming with read/write suffixes (e.g., `_tags`, `_desc`)
- **Smart Wildcard System**: Use `%description%` to read existing file content in prompts
- **Selectable Image Management**: Visual thumbnail selection with bulk operations
- **Progress Tracking**: Real-time progress feedback during batch operations
- **Flexible Output Options**: Choose to overwrite existing files or append new content

### ÔøΩüí¨ Advanced Chat Features

- **Chat History**: Automatic conversation saving with intelligent title generation
- **AI-Powered Titles**: Smart conversation titles using AI analysis (configurable)
- **New Chat Management**: Easy conversation switching with auto-save
- **Message Threading**: Non-blocking UI with streaming response support
- **Image Attachments**: Multi-image support with preview and clipboard integration

### üóÇÔ∏è Data Management

- **SQLite Database**: Local caching for models, conversations, and application state
- **Conversation Search**: Browse and manage chat history with deletion capabilities
- **Configuration System**: Comprehensive settings with UI preferences and chat defaults
- **Export/Import**: Save and share conversations (planned)

### üé® User Experience

- **Tabbed Interface**: Organized chat, batch processing, and history views
- **Responsive Design**: Async operations prevent UI freezing during model operations
- **Column Sorting**: Clickable headers for model list organization
- **Progress Tracking**: Visual feedback for model downloads and operations
- **Error Handling**: User-friendly error messages and logging

### üîß Technical Features

- **Modular Architecture**: Clean separation with manager classes (Backend, Menu, Layout, Tab)
- **Background Processing**: Non-blocking model operations and chat streaming
- **Memory Management**: Efficient handling of large models and conversations
- **Cross-Platform**: Works on Windows, macOS, and Linux
- **Extensible Architecture**: Modular design for easy feature additions

## Prerequisites

- Python 3.8 or higher
- [Ollama](https://ollama.com/download) installed and running
- At least one Ollama model installed (e.g., `ollama pull llama3`)

## Installation

### From Source

1. Clone the repository:

```bash
git clone https://github.com/arcum42/llamalot.git
cd llamalot
```

2. Create a virtual environment (recommended):

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Install the package in development mode:

```bash
pip install -e .
```

### Using pip (when published)

```bash
pip install llamalot
```

## Usage

### Running the Application

```bash
# From the project directory with virtual environment activated
source venv/bin/activate  # On Windows: venv\Scripts\activate
PYTHONPATH=/home/arcum42/Projects/personal/llamalot/src python -m llamalot.main

# Or using the entry point script
python main.py
```

### Configuration

The application stores its configuration and logs in:

- Linux/macOS: `~/.llamalot/`
- Windows: `%USERPROFILE%\.llamalot\`

### Managing Chat History

LlamaLot automatically saves all your conversations with intelligent features:

#### üìö Viewing Chat History

1. **Access History**: Click the "üìö History" tab in the main interface
2. **Browse Conversations**: View all past conversations with titles, models used, and timestamps
3. **Select Conversations**: Click any conversation to view the full chat content
4. **Smart Titles**: Conversations get intelligent titles like "Python list comprehensions - 2025-08-08"

#### üí¨ Managing Conversations

- **Auto-Save**: Conversations are automatically saved after each message exchange
- **New Chat**: Click "New Chat" button to start fresh (auto-saves current conversation)
- **Model Switching**: Switching models automatically saves the current conversation
- **Delete Conversations**: Select any conversation and click "Delete" (with confirmation)

#### ü§ñ AI-Powered Titles

- **Smart Naming**: For longer conversations (4+ messages), AI generates descriptive titles
- **Configurable**: Enable/disable in Settings ‚Üí "Use AI-generated conversation titles"  
- **Fallback**: Short conversations use cleaned first message + date

### Batch Image Processing

LlamaLot includes a powerful batch processing system for analyzing multiple images:

#### üîß Setting Up Batch Processing

1. **Navigate to Batch Tab**: Click the "üñºÔ∏è Batch" tab in the main interface
2. **Select Vision Model**: Choose a model with vision capabilities from the dropdown
3. **Add Images**: Click "Add Images" to select multiple image files
4. **Configure Prompt**: Enter your analysis prompt with optional wildcards

#### üìù Using Wildcards and File Suffixes

- **`%description%` Wildcard**: Includes content from existing text files
- **Read Suffix**: Specify suffix for files to read (e.g., `_tags` reads from `image1_tags.txt`)
- **Write Suffix**: Specify suffix for output files (e.g., `_desc` writes to `image1_desc.txt`)

#### üí° Example Workflows

**Workflow 1: Basic Description Generation**
- Images: `photo1.jpg`, `photo2.jpg`
- Prompt: `"Describe this image in detail"`
- Write Suffix: `_description`
- Result: Creates `photo1_description.txt`, `photo2_description.txt`

**Workflow 2: Enhanced Analysis with Existing Tags**
- Images: `photo1.jpg`, `photo2.jpg` 
- Existing files: `photo1_tags.txt`, `photo2_tags.txt`
- Prompt: `"Based on these tags: %description%, write a detailed description"`
- Read Suffix: `_tags`
- Write Suffix: `_enhanced`
- Result: Reads existing tag files, creates enhanced descriptions

### Using Embeddings & RAG

Enhance your chat conversations with contextual document search:

#### üìö Setting Up Collections

1. **Navigate to Embeddings Tab**: Click "üîç Embeddings" in the main interface
2. **Create Collection**: Click "Create Collection" and name your document set
3. **Add Documents**: Import text files, paste content, or add web articles
4. **Automatic Processing**: Documents are chunked and embedded automatically

#### üîç Using RAG in Chat

1. **Enable Context Search**: Toggle RAG integration in embeddings panel
2. **Start Chatting**: Ask questions related to your document collections
3. **Automatic Enhancement**: Relevant context is automatically retrieved and included
4. **View Sources**: See which documents contributed to each response

### Using Vision Models

LlamaLot supports vision models that can analyze images:

1. **Select a vision model** (models with vision capabilities):
   - `llama3.2-vision:latest`
   - `llava:7b` or other LLaVA variants  
   - `gemma3:12b`
   - Any model with "vision" in its capabilities

2. **Attach images to your chat**:
   - Click the "üìé Attach Images" button
   - Select one or multiple image files (PNG, JPG, GIF, BMP, WebP)
   - Preview attached images before sending
   - Double-click any preview image to view it full-size
   - Right-click on full-size images to copy them to the clipboard (or use Ctrl+C)
   - Remove individual images with the "‚úï" button

3. **Send messages with images**:
   - Type your question about the image(s)
   - Click "Send" or press Enter
   - The model will analyze the attached images and respond

4. **Supported formats**: PNG, JPEG, GIF, BMP, WebP

### Creating Custom Models

Use the built-in model creation wizard:

1. **Access Creator**: Click "Create Model" button in the model list
2. **Choose Base Model**: Select an existing model as foundation
3. **Edit Modelfile**: Use syntax-highlighted editor with real-time validation
4. **Set Parameters**: Configure temperature, system prompts, and other settings
5. **Create Model**: Monitor progress with real-time status updates

## Changelog

See [CHANGELOG.md](CHANGELOG.md) for a detailed history of changes and releases.

## Development Credits

LlamaLot was primarily developed through an AI-assisted programming approach, with extensive use of **GitHub Copilot** powered by **Claude 3.5 Sonnet**. This collaborative human-AI development process enabled rapid prototyping, comprehensive feature implementation, and robust error handling. (Okay, yeah, I let the AI write the Readme too. :P )

### AI-Assisted Development Highlights

- **Intelligent Code Generation**: Core application architecture and GUI components
- **Feature Implementation**: Chat history, conversation management, and title generation
- **Error Handling**: Comprehensive exception handling and user feedback systems  
- **Documentation**: API documentation, code comments, and user guides
- **Testing & Debugging**: Automated testing scenarios and bug identification

The combination of human creativity and direction with AI's code generation capabilities resulted in a feature-rich, stable application that might have taken significantly longer to develop using traditional methods alone.

## Development

### Setting up the Development Environment

1. Clone the repository and install dependencies as above

2. Install development dependencies:

```bash
pip install -e ".[dev]"
```

3. Run tests:

```bash
pytest
```

4. Format code:

```bash
black src/ tests/
```

5. Type checking:

```bash
mypy src/
```

### Project Structure

```text
llamalot/
‚îú‚îÄ‚îÄ .github/                     # GitHub configuration
‚îÇ   ‚îî‚îÄ‚îÄ copilot-instructions.md # Development guidelines
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ llamalot/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ main.py              # Application entry point
‚îÇ       ‚îú‚îÄ‚îÄ gui/                 # GUI components
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ components/      # Reusable GUI components
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dialogs/         # Dialog windows
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ managers/        # Manager classes (Backend, Menu, Layout, Tab)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tabs/            # Tab implementations
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ windows/         # Main windows (main_window.py)
‚îÇ       ‚îú‚îÄ‚îÄ backend/             # Backend logic
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py # Ollama API client
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ database.py      # Local database operations
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ cache.py         # Model caching system
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configuration management
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ embeddings_manager.py # Embeddings and RAG support
‚îÇ       ‚îú‚îÄ‚îÄ models/              # Data models
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ollama_model.py  # Ollama model representation
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configuration models
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ chat.py          # Chat conversation models
‚îÇ       ‚îî‚îÄ‚îÄ utils/               # Utilities
‚îÇ           ‚îî‚îÄ‚îÄ logging_config.py # Logging setup
‚îú‚îÄ‚îÄ tests/                       # Test files
‚îú‚îÄ‚îÄ test_images/                 # Test images for development
‚îú‚îÄ‚îÄ scripts/                     # Development and demo scripts
‚îú‚îÄ‚îÄ main.py                      # Main entry point
‚îú‚îÄ‚îÄ requirements.txt             # Dependencies
‚îú‚îÄ‚îÄ pyproject.toml              # Modern Python packaging
‚îú‚îÄ‚îÄ CHANGELOG.md                 # Version history
‚îî‚îÄ‚îÄ README.md                   # This file
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Useful Ollama Resources

### Documentation

- [Ollama API Reference](https://ollama.readthedocs.io/en/api/)
- [Modelfile Reference](https://ollama.readthedocs.io/en/modelfile/)
- [Quickstart Guide](https://ollama.readthedocs.io/en/quickstart/)
- [Importing Models](https://ollama.readthedocs.io/en/import/)
- [Troubleshooting](https://ollama.readthedocs.io/en/troubleshooting/)
- [FAQ](https://ollama.readthedocs.io/en/faq/)
- [Development Guide](https://ollama.readthedocs.io/en/development/)

### Related Projects

- [Ollama Official Website](https://ollama.com/)
- [Ollama Model Library](https://ollama.com/search)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [Ollama Python Library](https://github.com/ollama/ollama-python)
- [Ollama JavaScript Library](https://github.com/ollama/ollama-js)

## Acknowledgments

- **[Ollama](https://ollama.com/)** for the excellent local LLM platform that makes this application possible
- **[wxPython](https://wxpython.org/)** for the robust cross-platform GUI framework
- **[GitHub Copilot](https://github.com/features/copilot)** and **[Claude 3.5 Sonnet](https://claude.ai/)** for AI-assisted development that accelerated feature implementation
- **The open-source community** for all the amazing tools, libraries, and resources that made this project possible
- **Local LLM enthusiasts** who provide feedback and feature requests to improve the application
